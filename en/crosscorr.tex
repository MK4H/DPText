
\chapter{Cross-correlation}
\label{sec:cross-corr}
%\addcontentsline{toc}{chapter}{Cross-correlation}

% TODO: Cite wikipedia or find some other introduction
In this chapter, we define cross-correlation and its variants. We first define one-dimensional cross-correlation, extending it into multiple dimensions and introducing circular cross-correlation. We then describe how these variations are used to compute cross-correlation using Fast Fourier transform. Lastly we describe the possibilities for optimization and parallelization of cross-correlation, with real-world usage examples where these optimizations could be used.
% TODO: Maybe mention different data layouts such as one_to_one, one_to_many etc.


\section{Definition}

Cross-correlation, also known as sliding dot product or sliding inner-product, is a function describing similarity of two series or two functions based on their relative displacement \citep{site:wiki_cross_corr}.
Cross-correlation of functions $f,g: \mathbb{C} \rightarrow \mathbb{R}$, denoted as \(f \star g\), is defined by the following formula:
\[
	(f \star g)(\tau) = \int_{-\infty}^{\infty} \overline{f(t)}g(t + \tau) \,dt,
\] 

where \(\overline{f(t)}\) denotes the complex conjugate of \(f(t)\) and \(\tau\) is the displacement of the two functions \(f\) and \(g\). In simpler words, the value \((f \star g)(\tau)\) tells us how similar the function \(f\) is to \(g\) when \(g\) is shifted by \(\tau\), with higher value representing higher similarity. Figure \ref{fig:cross_corr_example} shows cross-correlation of two example functions.

\begin{figure}[h]
	\centering
	\def\svgwidth{0.8\textwidth}
	% Must be relative to current directory
	% as input ignores graphicspath, which is
	% only for includegraphics{}
	\input{./img/crosscorr.pdf_tex}
	\caption{Cross-correlation of two functions. \cite{pic:crosscorr}}
	\label{fig:cross_corr_example}
\end{figure}

For two discrete functions, as will be used in our case, cross-correlation of functions \( f, g : \mathbb{Z} \rightarrow \mathbb{R} \) is defined by the following formula:

\[
(f \star g)[m] = \sum_{i=-\infty}^{\infty} \overline{f[i]}g[i + m],
\] 



This definition of cross-correlation can be extended for use in two dimensions, as is required, for example, in image processing.
For two discrete functions \( f, g : \mathbb{Z}^2 \rightarrow \mathbb{R} \), cross-correlation is defined as:

\[
(f \star g)[m,n] = \sum_{i=-\infty}^{\infty} \sum_{j=-\infty}^{\infty} \overline{f[m,n]}g[m + i,n + j],
\]

Even though cross-correlation is defined on the whole $\mathbb{Z}$ for one dimension and $\mathbb{Z}^2$ for two dimensions, most use cases of cross-correlation work only on finite inputs, such as image processing working on finite images. The only values we are interested in are when the two images overlap, which limits the computation to $(w_1 + w_2 - 1) * (h_1 + h_2 - 1)$, where $w_i$ denotes width of the image $i$ and $h_i$ denotes the height of the image $i$.

This limits the part of the output we are interested in and leads us to time complexity of the definition based algorithm, or \textit{naive} algorithm as it is called in the code associated with the thesis. For each of the $(w_1 + w_2 - 1) * (h_1 + h_2 - 1)$ output values, we need to multiply the overlapping pixel values and sum all the multiplication results together. There will be at most $min(w_1, w_2) * min(h_1, h_2)$ overlapping pixels. For simplicity, let us work with two images of size $w_i*h_i$. Then the time complexity of the definition based algorithm is $((2*w_i-1)*(2 * h_i - 1) * (w_i * h_i))$, which gives us asymptotic complexity of $\mathcal{O}(w_i^2*h_i^2)$.

\section{Computation using discrete Fourier Transform}
\label{sec:cross_corr_fft}

In this section, we describe an algorithm which uses discrete Fourier transform to compute cross-correlation of two finite two-dimensional series. The asymptotic complexity of this algorithm will be $\mathcal{O}(w_i*h_i*\log_2(w_i*h_i))$, where $w_i$ is the width of each series and $h_i$ the height of each series. This improves on the asymptotic complexity $\mathcal{O}(w_i^2*h_i^2)$ of the definition based algorithm described in the previous section \ref{sec:cross-corr}.

Discrete Fourier transform can only be used to compute a special type of cross-correlation, so called \textit{circular} cross-correlation.
For finite series $N \in \mathbb{N} \{x\}_n = x_0, x_1, ..., x_{N-1}, \{y_n\} = y_0, y_1, ..., y_{N-1}$, circular cross-correlation is defined as:

\[
(x \star_N y)_m = \sum_{i=0}^{N-1} \overline{x_m} y_{(m + i) mod N},
\]

where $\overline{x_m}$ denotes complex conjugate of $x_m$.


Based on the Cross-Correlation Theorem \citep{thesis:wang}, circular cross-correlation $(x \star_N y)_m$ can be computed using discrete Fourier Transform based on the following formula:

\[
(x \star_N y)_m = \mathbb{F}^{-1}(\overline{\mathbb{F}(x)}*\mathbb{F}(y))
\]

where $\mathbb{F}(x)$ and $\mathbb{F}(y)$ denote discrete Fourier Transform of series $x$ and $y$ respectively, $\overline{\mathbb{F}(x)}$ denotes complex conjugate of the discrete Fourier Transform, $*$ denotes element-wise multiplication of two series and $\mathbb{F}^{-1}$ denotes inverse discrete Fourier Transform.

As described by \citep{misko}, to compute non-circular (linear) cross-correlation of non-periodic series of size \textit{N}, such as an image, we pad both series with \textit{N} zeroes to size \textit{2N}. The results of circular cross-correlation are then the results of linear cross-correlation, just circularly shifted by $N-1$ places to the right with one additional 0 value. 

% TODO: Maybe steal image from misko

This process can be expanded into two dimensions, where we pad the images with \textit{N} rows and \textit{N} columns of zeroes, compute 2D discrete Fourier transform. Here the circular shift of the results can be inverted by swapping top-left with bottom-right and top-right with bottom-left quadrants, while discarding row \textit{N} and column \textit{N} which will be zero \citep{misko}. 

% TODO: Again maybe steal image from misko

Based on this description, we can deduce the time complexity of the algorithm. For two matrices $a,b \in \mathbb{R}^{h \times w}$,the steps of the algorithm are:
\begin{enumerate}
	\item Padding $a_p, b_p \in \mathbb{R}^{2h \times 2w}$ of $a$ and $b$ with $h$ rows and $w$ columns of zeroes in $\mathcal{O}(h*w)$;
	\item Discrete Fourier Transform $A,B 
	in \mathbb{C}^{2h \times 2w}$ $A$ of $a_p$ and $B$ of $b_p$ in $\mathcal{O}(h*w*\log_2(h*w))$;
	\item Element-wise multiplication, also known as Hadamard product, $C \in \mathbb{C}^{2h \times 2w}: C = \overline{A} \circ B$, where $\overline{A}$ denotes complex conjugate of $A$, in $\mathcal{O}(w_i*h_i)$;
	\item Discrete Fourier Transform $c \in \mathbb{R}^{2h \times 2w}$ of $C$ in $\mathcal{O}(h*w*\log_2(h*w))$;
	\item Quadrant swap in $\mathcal{O}(h*w)$
\end{enumerate}

Put together, the steps described above give us an algorithm with asymptotic time complexity of $\mathcal{O}(h*w*\log_2(h*w))$.

\section{Parallelization and optimizations}
In the original thesis by \citep{misko}, and in the field of image processing in general, 2D version of cross-correlation is mostly used to find a grayscale image or a piece of a grayscale image represented as integer or floating point matrix in another image. This can be done to for example find a displacement of a certain point of interest between images of one item taken at different times, as is done in \citet{misko} and \citet{zhang2015}. 

This thesis will implement cross-correlation of integer and floating point matrices, which encompasses the usage in previously mentioned works. The implementations will be optimized to take advantage of different forms of cross-correlation input, such as cross-correlation of one matrix with many other matrices, different sizes of input matrices etc. 
% TODO: Expand

\subsection{Forms of cross-correlation}

In works using cross-correlation, there are several forms of computation which can be used for optimization such as data caching and reuse, batching, precomputing etc. The forms differ in the number of inputs and in the way cross-correlation is computed between different inputs. 
The two basic forms are:

\begin{enumerate}
	\item n left inputs, each with m different right inputs (n to mn) \citet{misko} \citet{zhang2015} \citet{Kapinchev2015}, 
	\item x left inputs, each with all y right different inputs (n to m) \citet{Clark2011}.
\end{enumerate} 

There are several subtypes which can also be optimized for. For \textit{n} left inputs with disjoint sets of \textit{m} right inputs for each of the left inputs, we have the following subtypes:

\begin{enumerate}
	\item one to one,
	\item one to many,
	\item large number of pairs.
\end{enumerate}

With these subtypes, we can more aggressively cache and reuse the left input. Any implementation capable of processing the general input form can also be used to implement all of these subtypes.
% We use this with the warp shuffle and warp shift implementations
Inversely, optimized implementation of the any of the above subtypes can be used to implement the general n to mn input type and transitively any of the other subtypes.

Any implementation of the \textit{one to many} subtype can also be used to implement the other major type, the \textit{x to y} type, by running the \textit{one to many} \textit{x} times, possibly in parallel.


%The following are examples of cross-correlation usage:
%\begin{itemize}
%	\item \citet{misko} computes cross-correlation between multiple subregions of a reference image with the corresponding subregion in multiple deformed images.
%	\item \citet{zhang2015} differs from \citep{misko} only in a processing that follows the cross-correlation phase which is outside the scope of this thesis.
%	\item \citet{Kapinchev2015} computes cross-correlation of one input signal with a number of masks to determine the values for all depths in parallel. The presented implementation does cross-correlation with each mask separately, computing them sequentially one after another, but this is due to the memory limitations of hardware and the optimal solution would be to compute the cross-correlation of the input signal with all masks in parallel.
%	\item \citet{Clark2011} computes cross-correlation of time series, where signal from each antenna with the signal from all other antennas.
	% TODO: Additional usecases
%\end{itemize}


\subsection{Post-processing}

In most use cases, cross-correlation itself is not a final output but the results are used further in further processing.

It is often used to find position of a smaller signal in larger signal, for example in the field of Digital image processing for template matching, image alignment etc. In these use cases, the only information of interest is the maximum value in the result matrix. 

In Digital Image correlation, we are also interested in finding the maximum, but this time with a subpixel precision. This requires us to find the maximum value and use the results in an area around it to interpolate a function \citep{zhang2015} \citep{misko}.

In the field of Seismology, cross-correlation is used for picking, ambient noise monitoring, waveform comparison and signal, event and pattern detection. \citep{Ventosa2019}
 
In optical coherence tomography, the whole result of cross-correlation summed to compute the intensity of each pixel \citep{Kapinchev2015}. 

Any post-processing is outside of the scope of this thesis. Result of cross-correlation will be taken as-is and validated against preexisting cross-correlation implementations.
% TODO: Go through the examples and see what they do with the results

% TODO: Post processing, what is the usual output etc.
% TODO: Menion that we are not doing any postprocessing

