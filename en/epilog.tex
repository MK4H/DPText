\chapter*{Conclusion}
\addcontentsline{toc}{chapter}{Conclusion}
 
In this thesis, we have analyzed the definition-based cross-correlation algorithm, searching for parallelization and optimization possibilities based on the input matrix size and input type. Based on this analysis, we have implemented two algorithm families, each with many implementations employing different combinations of the optimization and parallelization strategies. The implementations are based on the CUDA framework.

The optimizations target many algorithm properties, from caching and data reuse with the goal of reducing the number of accesses to slower memory types, to the amount of parallelism available to fully saturate the GPU and utilize the full throughput provided by the hardware. Each optimization was rigorously profiled and measured for different input sizes and input types, some trying to optimize across all inputs and some targeting specific combinations of input sizes and types. 

The first algorithm family presented by this thesis was the Warp shuffle family, which utilized warp shuffle instructions to share input data between threads of a warp, significantly reducing the number of accesses to global memory. The family includes further optimizations, which reduce the total number of warp shuffle instructions required. This is achieved by computing cross-correlation between one matrix and many other matrices at once or by computing multiple results from the same cross-correlation at once. Another optimization employed by this family improves parallelization and load balancing.
 
The second algorithm family was the Warp per shift family, which improved occupancy by utilizing a whole warp to compute a single element in the output matrix. This family includes optimizations for data reuse and cooperation of warps through shared memory, together with further improvements to occupancy by utilizing multiple warps per single output matrix element.

We then compared the implementations introduced in this thesis against several other cross-correlation implementations. First, we compared our optimized implementations against a Basic definition-based CUDA implementation. Next, we compared them against an implementation based on the Fast Fourier Transform algorithm also using CUDA. Lastly, we compared our implementations with cross-correlation from production-grade libraries and toolkits, namely with the CPU-based implementation provided by the Python Scipy library and the GPU implementation provided by Matlab. 

When compared with the Basic definition-based CUDA implementation, our optimized implementation achieves at least 5 times speedup for most inputs and up to 10 to 80 times speedup for certain input sizes. When compared with the FFT-based implementation, we achieve speed parity for input matrix sizes over 100x100 for a smaller number of input matrices, decreasing down to 60x60 for a larger number of matrices. In comparison with the CPU-based SciPy library, our implementations achieve 50 times speedup for small input sizes and up to 3000 times speedup for larger input sizes. When compared with Matlab, we achieve around 5 times speedup for small input sizes.
 


\section{Future work}
Although the optimized implementations provided in this thesis are useful and achieve the speedups listed above, they are mostly designed for easy instrumentation and benchmarking. This results in several restrictions on the size and form of the input data, long build times, and a giant executable. In the future, the implementation could be streamlined and the limitations removed.

This thesis also focused heavily on utilizing the CUDA platform for the implementation of the optimized definition-based algorithms. Future work could be aimed at an implementation using other, currently less common tools such as OpenCL. 

Next, the implementations in this thesis utilize only a single GPU. In the future, the implementation could be expanded to utilize more GPUs on a single system or even further to utilize GPUs over multiple systems. Based on the inherent parallelism in the definition-based cross-correlation described in this thesis, the implementation of a distributed version could build on the work provided in this thesis very easily.

To further speed up the definition-based cross-correlation, additional properties of the input data could be used. This includes utilizing non-negative input data and terminating the parts of the computation which cannot reach the current maximum or computing a submatrix of the full cross-correlation matrix.