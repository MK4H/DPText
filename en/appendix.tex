% TODO: THis reference
% REFERENCE https://forums.developer.nvidia.com/t/loop-through-register-array-without-using-local-memory/29458/3
\chapter{Local array optimization}

\label{sec:local_array_optimization}

% Why is it important that the arrays are in registers
% REFERENCE https://developer.nvidia.com/blog/fast-dynamic-indexing-private-arrays-cuda/
All \textit{multimat} and \textit{multirow} optimizations heavily rely on the ability of the CUDA compiler to place arrays such as the following into registers:

\begin{lstlisting}[
style=cuda
]
template<size_t LENGTH>
__device__ void foo(...) {
	...
	float bar[LENGTH];
	for (size_t i = 0; i < LENGTH; ++i) {
		bar[i] = some_function(...);
	}
	...
}
\end{lstlisting}

% TODO: Quote the blog
If an array is small and only accessed using static indexing, where all indices are known constants at compile time, the CUDA compiler places all elements of the array into registers \citep{site:private_arrays_cuda}. The array can also be accessed in small for loops with known compile time bounds, which are unrolled by the compiler and again result in static indexing. If for any access the index cannot be computed during compile time, the whole array is placed into Local memory, described in Section \ref{sec:memory_hierarchy}. Local memory is part of the device memory, and as such is the slowest memory accessible from device code. Local memory access also utilizes the same pipeline as warp shuffle instructions, competing for the throughput of this pipeline. 


\section{Advanced optimizations and local arrays}
\label{sec:local_array_optimization_code_changes}

While implementing the \textit{multimat\_both} and \textit{multirow\_both} optimizations, which are described in  Sections \ref{sec:multimat_both} and \ref{sec:multirow_both} respectively, we encountered a problem with the \textit{nvcc} compiler not optimizing the local arrays into registers. 

Using profiling and examining the SASS, we isolated the problem to the \textit{thread\_left\_bottom} and \textit{thread\_left\_top} arrays. We further isolated it to the part of the code, which in its original form shared by the simplified, \textit{multimat\_right} and \textit{multirow\_right} is shown in Listing  \ref{lst:base_left_buffer_shuffle}.

\begin{lstlisting}[
style=cuda,
float,
caption=Base Warp shuffle implementation of left buffer shuffle,
label=lst:base_left_buffer_shuffle
]
thread_left_bottom = warp.shfl(
	warp.thread_rank() != 0 ? thread_left_bottom : thread_left_top,
	warp.thread_rank() + 1
);
thread_left_top = warp.shfl_down(thread_left_top, 1);
\end{lstlisting}

To process multiple values from left input matrices, which is the basis of both \textit{multimat\_both} and \textit{multirow\_both} optimizations, the code needs to be changed as shown in Listing \ref{lst:wrong_left_buffer_shuffle}

\begin{lstlisting}[
style=cuda,
float,
caption=Multimat both and multirow both implementation of left buffer shuffle,
label=lst:wrong_left_buffer_shuffle
]
#pragma unroll
for (size_t l = 0; l < NUM_LEFTS; ++l) {
	thread_left_bottom[l] = warp.shfl(
		warp.thread_rank() != 0 ? thread_left_bottom[l] : thread_left_top[l],
		warp.thread_rank() + 1
	);
	thread_left_top[l] = warp.shfl_down(thread_left_top[l], 1);
}
\end{lstlisting}

The \textit{nvcc} compiler should be able to unroll this loop, and thanks to static indexing, the \textit{thread\_left\_bottom} and \textit{thread\_left\_top} local arrays should be optimized into registers. Unfortunately, as shown in Listing \ref{lst:sass_local_mem}, the compiler behaves as if dynamic indexing was used and pushes the arrays into local memory. 
Due to the closed source nature of the \textit{nvcc} compiler, we can only speculate on the reasons why the loop unrolling does not result in static indexing. One possibility, based on the generated SASS instructions seen in Listing \ref{lst:sass_local_mem}, is that the ternary operator is optimized into dynamic array indexing, which then prevents the local array optimization. As there is no visible branching in the unrolled loop, the base address of either the \textit{thread\_left\_bottom} or the \textit{thread\_left\_top} is loaded into register R63, which is then reused in all loads, resulting in dynamic indexing. 

% TODO: Add coloring
\begin{lstlisting}[
style=sass,
float,
caption={SASS instructions without local array optimization},
label=lst:sass_local_mem
]
LDL R0, [R63+0x4]
SHFL.IDX PT, R8, R0, R57, 0x1f
SHFL.DOWN PT, R0, R32, 0x1, 0x1f
STL [R62], R8
STL [R61], R0
\end{lstlisting}

We experimented with several solutions, with version in Listing \ref{lst:fixed_left_buffer_shuffle} compiling into static indexing.

\begin{lstlisting}[
style=cuda,
float,
caption=Fixed multimat both and multirow both implementation of left buffer shuffle,
label=lst:fixed_left_buffer_shuffle
]
#pragma unroll
for (size_t l = 0; l < NUM_LEFTS; ++l) {
	T bottom_shift_val;
	if (warp.thread_rank() != 0) {
		bottom_shift_val = thread_left_bottom[l];
	} else {
		bottom_shift_val = thread_left_top[l];
	}

	thread_left_bottom[l] = warp.shfl(bottom_shift_val, warp.thread_rank() + 1);
	thread_left_top[l] = warp.shfl_down(thread_left_top[l], 1);
}
\end{lstlisting}

% TODO: Add coloring
\begin{lstlisting}[
style=sass,
float,
caption={SASS instructions with local array optimization},
label=lst:sass_no_local_memory
]
SEL R42, R52, R20, !P4
SHFL.IDX PT, R53, R48, R53, 0x1f
SHFL.DOWN PT, R52, R52, 0x1, 0x1f
\end{lstlisting}

The only change is the expansion of the ternary operator into an equivalent if statement. As shown in Listing \ref{lst:sass_no_local_memory}, the body of the updated loop results in a single \textit{SEL} instruction which selects the top or the bottom part of the buffer. This version of the loop is used by the \textit{multimat\_both} and \textit{multirow\_both} optimizations described in the following sections.

The difference is also noticeable when profiling, which shows additional local memory store (STL) and load (LDL) instructions in both the \textit{multimat\_both} and \textit{multirow\_both} without local array optimization. Apart from these additional instructions, the number of remaining instructions is generally the same, with some additional integer multiply-add instructions (IMAD) due to local memory address computations.

Based on this observation, the measured speedup in Figure \ref{fig:speedup_local_mem} is caused solely by the application of the local array optimization. The speedup for smaller inputs is limited due to low occupancy, but is still present. As an example, Figure \ref{fig:multimat_both_speedup} shows that for input matrices of size 64 by 64, the solution without local memory access is already 2 times faster. Figure \ref{fig:multirow_both_speedup} shows that there is slightly smaller improvement in the \textit{multirow\_both} optimization compared to the \textit{multimat\_both}. This is most likely caused by higher general overhead due to the greater overall complexity of the optimization.


\begin{figure}[ht]
	\centering	
	\begin{subfigure}{0.45\textwidth}
		\centering
		\def\svgwidth{\textwidth}
		% Must be relative to current directory
		% as input ignores graphicspath, which is
		% only for includegraphics{}
		\input{./img/multimat_speedup.pdf_tex}
		\caption{The \textit{multimat\_both} optimization.}
		\label{fig:multimat_both_speedup}
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.45\textwidth}
		\centering
		\def\svgwidth{\textwidth}
		% Must be relative to current directory
		% as input ignores graphicspath, which is
		% only for includegraphics{}
		\input{./img/multirow_speedup.pdf_tex}
		\caption{The \textit{multirow\_both} optimization.}
		\label{fig:multirow_both_speedup}
	\end{subfigure}
	
	\caption{Improvement of the two optimizations without local memory access.}
	\label{fig:speedup_local_mem}
\end{figure}




\chapter{Attachments}

In the attachments to this thesis we include the source code of our CUDA C++ implementation and the benchmarking tool, together with the profiling and measurement results and the Jupyter Notebooks used for visualization of the measured results. The attachments contain the following directories:

\begin{itemize}
	\item \texttt{src} - Source code of the CUDA C++ program implementing the definition-based and FFT-based algorithms for cross-correlation. Contains all the kernels referenced in Chapter \ref{sec:implementation}.
	\item \texttt{benchmarking} - The Benchmarking tool described in Section \ref{sec:experiments}.
	\item \texttt{existing} - Code allowing the use of cross-correlation implementations in Python SciPy and Matlab.
	\item \texttt{visualization} - Jupyter Notebooks and Python code used to process results generated by the Benchmarking tool and generate the diagrams shown in this text.
	\item \texttt{gpulab} - Helper scripts for building and running the CUDA C++ application and Benchmarking tool both locally and on the KSI Cluster gpulab.
	\item \texttt{profiling} - Results of profiling the CUDA C++ implementation using NVIDIA Nsight Compute tool.
	\item \texttt{sample\_app} - A sample application showcasing the steps required to utilize one of the implementations provided by this thesis in another application.
\end{itemize}

Detailed description is included in the attachments.